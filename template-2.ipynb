{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Some questions we brainstormed:\n",
    "\n",
    "# Is it possible to make a high accuracy model that can predict wins and losses if given data on team performance?\n",
    "# How much does the duration of a game impact the win statistics of different teams?\n",
    "# Does opponent gold influence the team kills per minute and final result? If so, how much?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "from lec_utils import *\n",
    "import lec23_util as util\n",
    "## This extracts out all of the code \n",
    "pd.options.plotting.backend = 'plotly'\n",
    "df = pd.read_csv('eecs398Sheet.csv', usecols=[\"teamname\", \n",
    "                                              \"result\",\n",
    "                                              \"team kpm\",  \n",
    "                                              \"kills\", \n",
    "                                              \"deaths\", \n",
    "                                              \"firstmidtower\", \n",
    "                                              \"towers\", \n",
    "                                              \"totalgold\"])\n",
    "df = df.dropna()\n",
    "# df = df[df[\"result\"] != 1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(df[['team kpm', 'totalgold']], df['result'], random_state=1)\n",
    ")\n",
    "fig = (\n",
    "    X_train.assign(result=y_train.astype(str).replace({'1': 'Win', '0': 'Loss'}))\n",
    "            .plot(kind='scatter', x='team kpm', y='totalgold', color='result', \n",
    "                  color_discrete_map={'Win': 'orange', 'Loss': 'blue'},\n",
    "                  title='Relationship between total gold, team kpm, and final result of the match')\n",
    "            .update_layout(\n",
    "                xaxis=dict(title='Team KPM', range=[0, 2.5]),  # Adjust the range for x-axis\n",
    "                yaxis=dict(title='Total Gold', range=[20000, 120000]),  # Adjust the range for y-axis\n",
    "                width=800\n",
    "            )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##bivariate analysis\n",
    "first_tower_games = df[df['firstmidtower'] == 1]\n",
    "\n",
    "win_rate = (first_tower_games['result'] == 1).mean() * 100\n",
    "lose_rate = 100 - win_rate\n",
    "\n",
    "labels = ['Win with First Tower', 'Loss with First Tower']\n",
    "sizes = [win_rate, lose_rate]\n",
    "colors = ['#00C49F', '#FF8042']\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "        startangle=90,\n",
    "        counterclock=True,\n",
    "        pctdistance=0.85,\n",
    "        radius=1,\n",
    "        wedgeprops=dict(width=0.7),\n",
    "        textprops={'fontsize': 8, 'fontfamily': 'sans-serif'})\n",
    "\n",
    "plt.title('Percentage of Team Winning with First Tower', \n",
    "          pad=15, \n",
    "          size=10,\n",
    "          fontfamily='sans-serif')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"When getting first tower:\")\n",
    "print(f\"Win rate: {win_rate:.1f}%\")\n",
    "print(f\"Lose rate: {lose_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis using KPM\n",
    "\n",
    "kpm_plot = df['team kpm'].plot(\n",
    "    kind='histogram',\n",
    "    nbins=75,\n",
    "    title='Kills per Minute (KPM) Distribution Across All Games',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "kpm_plot.update_layout(\n",
    "    xaxis_title='Team KPM',\n",
    "    yaxis_title='Number of Games'\n",
    ")\n",
    "\n",
    "kpm_plot.show()\n",
    "\n",
    "print(f\"Mean KPM: {df['team kpm'].mean():.2f}\")\n",
    "print(f\"Median KPM: {df['team kpm'].median():.2f}\")\n",
    "print(f\"Std: {df['team kpm'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpm_plot.write_html('../league-of-legends-analysis/assets/kpm_univariate.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univeriate analysis using Towers\n",
    "towers_plot = df['towers'].value_counts().sort_index().plot(\n",
    "    kind='bar',\n",
    "    title='Towers Destroyed By a Team In a Single Game',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "towers_plot.update_layout(\n",
    "    xaxis_title='Number of Towers Taken',\n",
    "    yaxis_title='Number of Games'\n",
    ")\n",
    "\n",
    "towers_plot.show()\n",
    "\n",
    "print(f\"Mean towers taken: {df['towers'].mean():.2f}\")\n",
    "print(f\"Mode: {df['towers'].mode().iloc[0]}\")\n",
    "print(f\"Median: {df['towers'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Made a scatter plot to shpw diversity of the data we are working with here.\n",
    "df2 = pd.read_csv('eecs398Sheet.csv', usecols=[\"teamname\", \n",
    "                                              \"teamid\",\n",
    "                                              \"result\",\n",
    "                                              \"team kpm\",  \n",
    "                                              \"kills\", \n",
    "                                              \"deaths\", \n",
    "                                              \"firstmidtower\", \n",
    "                                              \"towers\", \n",
    "                                              \"totalgold\"])\n",
    "df2 = df.dropna()\n",
    "fig = px.scatter(\n",
    "    df2, \n",
    "    x=\"team kpm\", \n",
    "    y=\"totalgold\", \n",
    "    color=\"teamname\", \n",
    "    hover_data=[\"result\", \"kills\", \"deaths\"], \n",
    "    title=\"Scatter Plot of Total Gold vs Team KPM\",\n",
    "    labels={\"totalgold\": \"Total Gold\", \"team kpm\": \"Team KPM\"}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Made the combined DataFrame here. This part is critical for our model.\n",
    "df2 = df[df[\"result\"] != 1]\n",
    "df4 = df[df[\"result\"] != 0]\n",
    "df2.reset_index()\n",
    "columns = len(df2) // 90\n",
    "df2['group'] = np.arange(len(df2)) // columns\n",
    "df2['group'] = df2['group'].clip(upper=90 - 1)\n",
    "aggregated_df = df2.groupby('group')[['team kpm', 'deaths', 'totalgold', 'firstmidtower']].mean().reset_index()\n",
    "aggregated_df['result'] = 0\n",
    "print(aggregated_df)\n",
    "df4.reset_index()\n",
    "columnname = len(df4) // 90\n",
    "print(columnname)\n",
    "df4['group'] = np.arange(len(df4)) // columns\n",
    "df4['group'] = df4['group'].clip(upper=90 - 1)\n",
    "aggregated_df2 = df4.groupby('group')[['team kpm', 'deaths', 'totalgold', 'firstmidtower']].mean().reset_index()\n",
    "aggregated_df2['result'] = 1\n",
    "print(aggregated_df2)\n",
    "combined_df = pd.concat([aggregated_df, aggregated_df2], ignore_index=True)\n",
    "print(combined_df)\n",
    "\n",
    "df2.reset_index()\n",
    "columns = len(df2) // 90\n",
    "df2['group'] = np.arange(len(df2)) // columns\n",
    "df2['group'] = df2['group'].clip(upper=90 - 1)\n",
    "aggregated_df = df2.groupby('group')[['team kpm', 'deaths', 'totalgold', 'firstmidtower']].mean().reset_index()\n",
    "print(aggregated_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# We are predicting whether or not a team wins a game based on the statistics we perceive \n",
    "# to have the highest impact on winning: team kills per minute, the first to capture the mid-tower,\n",
    "# the total gold of a team during the game, and the number of deaths the team accrued. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lec25_util\n",
    "#We run logistical regression on the combined DF split into bins.\n",
    "#Takes the train test split on the combined DF.\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(combined_df[['team kpm', 'totalgold', 'firstmidtower']], combined_df['result'], random_state=1)\n",
    ")\n",
    "\n",
    "def chooseWinner(X_train, y_train):\n",
    "    numeric_features = ['team kpm', 'totalgold', 'firstmidtower']\n",
    "    numeric_transformer = StandardScaler() ##Standardize all of the numeric features.\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features) ## Column Transformed\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LogisticRegression()) ## Pipeline into a Logistic Regression model.\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline\n",
    "pipeline = chooseWinner(X_train, y_train)\n",
    "pipeline\n",
    "input_data = pd.DataFrame([{ # Here Input the data used for predictions.\n",
    "    'team kpm': 0.6,\n",
    "    'totalgold': 58000,\n",
    "    'firstmidtower' : 1\n",
    "}])\n",
    "\n",
    "predicted_result = pipeline.predict_proba(input_data) # Predicts the Loss-Win rate.\n",
    "predicted_accuracy = pipeline.score(X_test, y_test) # Model Accuracy\n",
    "print(predicted_result)\n",
    "print(predicted_accuracy)\n",
    "lec25_util.show_confusion(X_test, y_test, T=0.5) # Outputs the confusion matrix,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lec25_util\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#We run logistical regression on the entire DF of thousands of results.\n",
    "#Takes the train test split on the entire DF.\n",
    "#Steps followed below are exactly like the last code block.\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(df[['team kpm', 'totalgold', 'firstmidtower']], df['result'], random_state=1)\n",
    ")\n",
    "\n",
    "def chooseWinner(X_train, y_train):\n",
    "    numeric_features = ['team kpm', 'totalgold', 'firstmidtower']\n",
    "    numeric_transformer = StandardScaler()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features)\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LogisticRegression())\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline\n",
    "pipeline = chooseWinner(X_train, y_train)\n",
    "pipeline\n",
    "input_data = pd.DataFrame([{\n",
    "    'team kpm': 0.6,\n",
    "    'totalgold': 38000,\n",
    "    'firstmidtower' : 1\n",
    "}])\n",
    "\n",
    "predicted_result = pipeline.predict_proba(input_data)\n",
    "predicted_accuracy = pipeline.score(X_test, y_test)\n",
    "print(predicted_result)\n",
    "print(predicted_accuracy)\n",
    "lec25_util.show_confusion(X_test, y_test, T=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model 1 Possibility - kNN Neigbbors with entire dataset. This is inefficient! And also more inaccurate!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Using Train Test Split on the large dataframe with entire dataset.\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(df[['team kpm', 'totalgold']], df['result'], random_state=1)\n",
    ")\n",
    "model_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': range(1, 100)} ## Use GridSearchCV to find the best k-Value\n",
    ")\n",
    "model_knn.fit(X_test, y_test)\n",
    "print(model_knn.score(X_test, y_test))\n",
    "# Visualize decision boundary\n",
    "best_k = model_knn.best_params_['n_neighbors']\n",
    "print(best_k) # Outputs the best_k value of 73. Pretty large number.\n",
    "#Output the chart\n",
    "util.show_decision_boundary(model_knn.best_estimator_, X_test, y_test, \n",
    "                            title='Decision Boundary')\n",
    "plt.xlim(0, 2.5)  # Set x-axis range\n",
    "plt.ylim(33000, 110000)  # Set y-axis range\n",
    "plt.show()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2: kNN Neighbors using Bins. Accuracy is far better!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Train Test Split data on the smaller dataframe.\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(combined_df[['team kpm', 'totalgold']], combined_df['result'], random_state=1)\n",
    ")\n",
    "model_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': range(1, 5)} #Use GridSearchCV to find best k value. It is 1 in this case.\n",
    ")\n",
    "model_knn.fit(X_test, y_test)\n",
    "print(model_knn.score(X_test, y_test))\n",
    "# Visualize decision boundary\n",
    "best_k = model_knn.best_params_['n_neighbors']\n",
    "print(best_k)\n",
    "util.show_decision_boundary(model_knn.best_estimator_, X_test, y_test, \n",
    "                            title='Decision Boundary')\n",
    "plt.xlim(0,1)  # Set x-axis range\n",
    "plt.ylim(40000, 65000)  # Set y-axis range\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 - Improved Initial Model as seen by the inclusion of deaths, the quantiled transformer on 3 columns\n",
    "import pandas as pd\n",
    "import lec25_util\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    train_test_split(df[['team kpm', 'totalgold', 'firstmidtower', 'deaths']], df['result'], random_state=1)\n",
    ")\n",
    "\n",
    "def chooseWinner(X_train, y_train):\n",
    "    numeric_features_normal = ['firstmidtower']\n",
    "    numeric_features_quantiled = ['team kpm', 'totalgold', 'deaths']\n",
    "    numeric_transformer = StandardScaler()\n",
    "    quantiled_transformer = QuantileTransformer() # Utilize QuantileTransformer to turn unnormal distributions into normal distributions.\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features_normal),\n",
    "            ('quant', quantiled_transformer, numeric_features_quantiled)\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LogisticRegression()) # Used Logistical Regression here\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train) #Fit the pipeline here.\n",
    "    return pipeline\n",
    "pipeline = chooseWinner(X_train, y_train)\n",
    "pipeline\n",
    "input_data = pd.DataFrame([{\n",
    "    'team kpm': 0.6,\n",
    "    'totalgold': 38000,\n",
    "    'firstmidtower' : 1,\n",
    "    'deaths' : 10\n",
    "}])\n",
    "\n",
    "predicted_result = pipeline.predict_proba(input_data)\n",
    "predicted_accuracy = pipeline.score(X_test, y_test)\n",
    "print(predicted_result)\n",
    "print(predicted_accuracy)\n",
    "lec25_util.show_confusion(X_test, y_test, T=0.5) #Output the decision matrix here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 4 Uses Decision Tree with a hyperparameter using GridSearchCV to determine the best tree depth.\n",
    "# The depth of this tree is pretty deep because of the amount of data, and is a little hard to read.\n",
    "# This model does have a far better accuracy, however, making it a stronger improvement from our initial model!\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import plot_tree\n",
    "# Complete train test split on the large dataframe.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['team kpm', 'totalgold', 'firstmidtower', 'deaths']], df['result'], random_state=1\n",
    ")\n",
    "\n",
    "def chooseWinner(X_train, y_train):\n",
    "    numeric_features_normal = ['firstmidtower']\n",
    "    numeric_features_quantiled = ['team kpm', 'totalgold', 'deaths']\n",
    "    numeric_transformer = StandardScaler() # Using Standard Scaler.\n",
    "    quantiled_transformer = QuantileTransformer() # Using Quantile Transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features_normal),\n",
    "            ('quant', quantiled_transformer, numeric_features_quantiled)\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=1)) #Applying Decision Tree Classifier.\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "pipeline = chooseWinner(X_train, y_train)\n",
    "param_grid = {\n",
    "    'classifier__max_depth': range(1,10),  # Depth of the tree. Using a range of values and having GridSearchCV finding the \n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_tree = best_pipeline.named_steps['classifier']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    feature_names=['team kpm', 'totalgold', 'firstmidtower', 'deaths'],\n",
    "    class_names=['Win', 'Loss'], \n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    impurity=False\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization (Max Depth = 6)\")\n",
    "plt.show()\n",
    "predicted_result = best_pipeline.predict(X_test)\n",
    "predicted_accuracy = best_pipeline.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", predicted_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 5 Uses Decision Tree with a hyperparameter using GridSearchCV to determine the best tree depth.\n",
    "# The depth of this tree is pretty small because the cpmbinedDF is binned, so this model is far more usable.\n",
    "# This model does has a perfect accuracy!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_df[['team kpm', 'totalgold', 'firstmidtower', 'deaths']], combined_df['result'], random_state=1\n",
    ")\n",
    "\n",
    "def chooseWinner(X_train, y_train):\n",
    "    numeric_features_normal = ['firstmidtower']\n",
    "    numeric_features_quantiled = ['team kpm', 'totalgold', 'deaths']\n",
    "    numeric_transformer = StandardScaler()\n",
    "    quantiled_transformer = QuantileTransformer()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features_normal),\n",
    "            ('quant', quantiled_transformer, numeric_features_quantiled)\n",
    "        ]\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', DecisionTreeClassifier(random_state=1))\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "pipeline = chooseWinner(X_train, y_train)\n",
    "param_grid = {\n",
    "    'classifier__max_depth': range(1,10),  # Depth of the tree\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "best_tree = best_pipeline.named_steps['classifier']\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    feature_names=['team kpm', 'totalgold', 'firstmidtower', 'deaths'],\n",
    "    class_names=['Loss', 'Win'], \n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    impurity=False\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization (Max Depth = 6)\")\n",
    "plt.show()\n",
    "predicted_result = best_pipeline.predict(X_test)\n",
    "predicted_accuracy = best_pipeline.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", predicted_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
